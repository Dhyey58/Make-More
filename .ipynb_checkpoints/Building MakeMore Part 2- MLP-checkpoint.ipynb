{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "dd066361-63a0-431f-980f-a7d46b60f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "7d63c991-1e32-4304-bebe-086a250a6c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all the words\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "ae5cedac-ff11-4ca2-8369-dab1d0f190ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "c5ff034d-4263-45f6-805f-f6baa2b38772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182580, 3]) torch.Size([182580])\n",
      "torch.Size([22767, 3]) torch.Size([22767])\n",
      "torch.Size([22799, 3]) torch.Size([22799])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  for w in words:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      # print(''.join(itos[i] for i in context), '--->', itos[ix])\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "# training split, dev/validation split, test split\n",
    "# 80%, 10%, 10%\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ce1d0c-741d-4341-bf9c-89c005eb9f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.shape, X.dtype, Y.shape, Y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "fb16f807-2124-4aba-bd22-5e57d439322a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182580, 3, 2])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 2)) #creating a vector to convert 27 characters in to two dimentional embedding\n",
    "emb = C[Xtr]               # assigning embedding the value of the train data set\n",
    "emb.shape                #so this converts 32 by 3 dataset into 2-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89a1e601-3aa4-4105-a093-d91e084338de",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn((6, 100))  #input is 6 because we have 3 2-D embeddings,beacuse we have contex of 3 so input=3*2\n",
    "                            # and we have 100 weights beacuse next hidden layer have 100 neuron\n",
    "b1 = torch.randn(100)       #bias is only for the next hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "446147bd-a6e3-472d-89cc-fab7b1887fb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (180x6 and 30x50)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[341], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtanh(emb\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m) \u001b[38;5;241m@\u001b[39m W1 \u001b[38;5;241m+\u001b[39m b1)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (180x6 and 30x50)"
     ]
    }
   ],
   "source": [
    "h = torch.tanh(emb.view(-1, 6) @ W1 + b1)  # we are converting shape of emb for matrix multiplication, we can use other method's also but this is most optimized\n",
    "                                           # we put -1 so the pyhton will figure out what to put there \n",
    "                                           # there will be 32 but we have put -1 for general solution\n",
    "                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa3db542-af16-49e4-a370-a7491ba5facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 100])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b25bb1a2-9520-4162-b386-5c22e5da4bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2 = torch.randn((100, 27))  # output is 27 because we want one of the character from 27 characters and 100 as input cause it is the output of the previous layer\n",
    "b2 = torch.randn(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0d0c4cf-7600-4271-8f73-93e5106579b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 27])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = h @ W2 + b2\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0a4aa2d-3eff-474b-bf3f-d7acb22740af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts = logits.exp()\n",
    "# prob = counts / counts.sum(1, keepdims=True)\n",
    "# prob.shape\n",
    "# loss = -prob[torch.arange(32), Y].log().mean()\n",
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ba5fa09-124e-4139-b08d-64ef1786d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------ now made respectable :) ---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "bc34ada5-bdbe-4325-9ba4-49d2c09a24b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([182580, 3, 10])"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.randn((27, 10)) #same as above but here for 10 dimension for better optimization\n",
    "emb = C[Xtr]               \n",
    "emb.shape                #so this converts 32 by 3 dataset into 10-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d92a96-db6a-43d8-a5b1-f7b9bf3e4563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "a1ab23f0-7e80-4846-aee7-14f1eb13d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C = torch.randn((27, 10), generator=g)\n",
    "W1 = torch.randn((30, 200), generator=g)*0.01\n",
    "b1 = torch.randn(200, generator=g)*0\n",
    "W2 = torch.randn((200, 27), generator=g)*0.01\n",
    "b2 = torch.randn(27, generator=g)*0\n",
    "parameters = [C, W1, b1, W2, b2]\n",
    "\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "6fde544a-cd3c-42d1-bb9c-c59d0d448cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11897"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters) # number of parameters in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "ce84579b-1c97-4d60-b0a8-bda23d42ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "lre = torch.linspace(-3, 0, 1000)  # we are doing this cause , by this we can step linearly between the exponents\n",
    "lrs = 10**lre             #this will create range from -0.001 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "bac14532-cb49-4af8-8050-5495a0cae352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3569650650024414\n"
     ]
    }
   ],
   "source": [
    "lri = []\n",
    "lossi = []\n",
    "stepi = []\n",
    "for i in range(200000):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (32,))  #(32,) because the output will be a 1-dimensional tensor with 32 elements instead of this we can also write (1,32)\n",
    "                                              # and this will create a small batch of 32 here we have take 32 beacause of upcoming matrix multiplication.\n",
    "  # forward pass\n",
    "  emb = C[Xtr[ix]] # (32, 3, 10)             # if you dont't want to take batch then use C[Xtr]\n",
    "  h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32,200) cause (32,3*10)\n",
    "  logits = h @ W2 + b2 # (32, 27)\n",
    "  loss = F.cross_entropy(logits, Ytr[ix])\n",
    "  # print(loss.item())\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr=0.1\n",
    "  #lr = lrs[i]\n",
    "  lr = 0.1 if i < 100000 else 0.01\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  #lri.append(lre[i])\n",
    "  stepi.append(i)\n",
    "  lossi.append(loss.log10().item())\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "0c041574-3f2f-430c-801d-9bf6c36a2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(stepi, lossi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "93a3e48f-da89-40b6-a61b-c6333fe8d123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1050, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xtr] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "66d9ae76-131f-49e1-a97d-f7d5596f25da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1410, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xdev] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eebf52-6b45-4c98-992f-083a9547fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize dimensions 0 and 1 of the embedding matrix C for all characters\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itos[i], ha=\"center\", va=\"center\", color='white')\n",
    "plt.grid('minor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf838f3-9826-453a-b4e2-f429804ff3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)\n",
    "      h = torch.tanh(emb.view(1, -1) @ W1 + b1)\n",
    "      logits = h @ W2 + b2\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e02affa-0bd4-4825-ae42-e90d9e163458",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (32,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0828455b-c3c7-4f8b-8e43-ec012d1eb73e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 10])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C[Xtr[ix]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5e656c19-e9d3-46c9-9339-12f96c0a1fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7dfa0d33-a242-4677-a3bf-730e6b3d7be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.1651, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xte] # (32, 3, 2)\n",
    "h = torch.tanh(emb.view(-1, 30) @ W1 + b1) # (32, 100)\n",
    "logits = h @ W2 + b2 # (32, 27)\n",
    "loss = F.cross_entropy(logits, Yte)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c6e3d-3a7f-40ca-a480-3b9169919040",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
